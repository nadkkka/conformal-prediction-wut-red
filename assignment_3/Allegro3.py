{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54bcf468-1162-4398-a1c6-70caec63422d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"Pierwsze 5 wierszy danych treningowych:\")\\nprint(train_data)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = r'C:\\Users\\Kamil\\Desktop\\II rok\\warsztaty\\Allegro\\data_red\\train_red.csv'\n",
    "#file_path = r'C:/Users/nadia/OneDrive/Pulpit/studia/II stopień/warsztaty badawcze/Allegro/data_red/train_red.csv'\n",
    "train_data = pd.read_csv(file_path) # wczytanie danych z pliku - zbiór treningowy\n",
    "\n",
    "file_path_2 = r'C:\\Users\\Kamil\\Desktop\\II rok\\warsztaty\\Allegro\\data_red\\test_red.csv'\n",
    "#file_path_2 = r'C:/Users/nadia/OneDrive/Pulpit/studia/II stopień/warsztaty badawcze/Allegro/data_red/test_red.csv'\n",
    "test_data = pd.read_csv(file_path_2) # wczytanie danych z pliku - zbiór testowy\n",
    "\n",
    "\"\"\"\n",
    "print(\"Pierwsze 5 wierszy danych treningowych:\")\n",
    "print(train_data)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a20e1c6-bba0-4e19-a2b0-e39e14858b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('imputer', SimpleImputer())])\n",
      "Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "                ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
      "ColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer', SimpleImputer())]),\n",
      "                                 Index(['SEG_2', 'SEG_3', 'FEAT_1', 'FEAT_2', 'FEAT_3', 'FEAT_4', 'FEAT_5',\n",
      "       'FEAT_6', 'FEAT_7', 'FEAT_8', 'FEAT_9', 'FEAT_10', 'FEAT_11'],\n",
      "      dtype='object')),\n",
      "                                ('cat',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                                 ('onehot',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                 Index([], dtype='object'))])\n",
      "ColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer', SimpleImputer())]),\n",
      "                                 Index(['SEG_2', 'SEG_3', 'FEAT_1', 'FEAT_2', 'FEAT_3', 'FEAT_4', 'FEAT_5',\n",
      "       'FEAT_6', 'FEAT_7', 'FEAT_8', 'FEAT_9', 'FEAT_10', 'FEAT_11'],\n",
      "      dtype='object')),\n",
      "                                ('cat',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                                 ('onehot',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                 Index([], dtype='object'))])\n",
      "[[2.00000000e+00 1.00000000e+00 9.16666667e-01 ... 1.90735695e-01\n",
      "  0.00000000e+00 1.55868534e-03]\n",
      " [5.00000000e+00 4.00000000e+00 2.50000000e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.00000000e+00 5.00000000e+00 7.50000000e-01 ... 4.57765668e-01\n",
      "  1.10590540e-03 0.00000000e+00]\n",
      " ...\n",
      " [5.00000000e+00 2.00000000e+00 1.66666667e-01 ... 0.00000000e+00\n",
      "  1.10812165e-02 2.75581502e-02]\n",
      " [4.00000000e+00 2.00000000e+00 4.16666667e-01 ... 0.00000000e+00\n",
      "  2.21624329e-05 0.00000000e+00]\n",
      " [2.00000000e+00 1.00000000e+00 9.16666667e-01 ... 0.00000000e+00\n",
      "  2.57439340e-03 1.55868534e-03]]\n",
      "['num__SEG_2' 'num__SEG_3' 'num__FEAT_1' 'num__FEAT_2' 'num__FEAT_3'\n",
      " 'num__FEAT_4' 'num__FEAT_5' 'num__FEAT_6' 'num__FEAT_7' 'num__FEAT_8'\n",
      " 'num__FEAT_9' 'num__FEAT_10' 'num__FEAT_11']\n"
     ]
    }
   ],
   "source": [
    "#dane treningowe - czyszczenie i zapisywanie ładnie\n",
    "train_y = train_data[\"TARGET\"]\n",
    "predictions_train = train_data[\"PRED\"]\n",
    "#train_X = train_data.drop(labels=[\"TARGET\", \"PRED\", \"residual\", \"lower_bound\", \"upper_bound\"], axis=1) #wersja kodu jeśli puszczamy po części 2\n",
    "train_X = train_data.drop(labels=[\"TARGET\", \"PRED\", \"PRED_BINNED\"], axis=1) # wyrzucamy wskazane kolumny\n",
    "train_X = pd.get_dummies(train_X) #to radzi sobie z categorical kolumnami - mozliwe ze dalszy kod by zadzialal bez tego - mozna sprawdzic\n",
    "\"\"\"\"Zamienia kolumny kategoryczne na numeryczne, ale czy SEG_1 to na pewno kolumna kategoryczna dla nas a SEG_2 i SEG_3 już nie? \n",
    "W SEG_1 występuje czasem wartość \"unknown\" i dlatego ta kolumna została potraktowana jako kategoryczna w przeciwieństwie do SEG_2 i SEG_3.\n",
    "Pytanie: czy te wszystkie trzy kolumny traktować jak numeryczne czy kategoryczne? Czy one w ogóle są potrzebne? Raczej nie, patrząc na polecenie zadania.\"\"\"\n",
    "#todo - usunąć usuwanie tych trzech kolumn przed wstawieniem na gita, bo to osobna część zadania w stosunku do drugiej.\n",
    "\n",
    "#dane testowe - to samo co z treningowymi, ale one nie maja dodatkowych kolumn\n",
    "test_y = test_data[\"TARGET\"]\n",
    "predictions_test = test_data[\"PRED\"]\n",
    "test_X = test_data.drop(labels=[\"TARGET\", \"PRED\"], axis=1)\n",
    "test_X = pd.get_dummies(test_X)\n",
    "\n",
    "# Identify categorical and numerical columns - train\n",
    "categorical_cols_train = train_X.select_dtypes(include=['object', 'category']).columns\n",
    "numerical_cols_train = train_X.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Identify categorical and numerical columns - test\n",
    "categorical_cols_test = test_X.select_dtypes(include=['object', 'category']).columns\n",
    "numerical_cols_test = test_X.select_dtypes(include=['number']).columns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Preprocessing for numerical data: impute missing values with mean\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "print(numerical_transformer)\n",
    "\n",
    "\n",
    "# Preprocessing for categorical data: impute missing values and one-hot encode\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "print(categorical_transformer)\n",
    "\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor_train = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols_train),\n",
    "        ('cat', categorical_transformer, categorical_cols_train)\n",
    "    ])\n",
    "print(preprocessor_train)\n",
    "\n",
    "preprocessor_test = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols_test),\n",
    "        ('cat', categorical_transformer, categorical_cols_test)\n",
    "    ])\n",
    "print(preprocessor_test)\n",
    "#todo zrobić jedną funkcję do której wkłada się kolumny dobre (teraz jest preprocessor_test i preprocessor_train)\n",
    "\n",
    "\n",
    "# Apply the transformations\n",
    "train_X = preprocessor_train.fit_transform(train_X)\n",
    "print(train_X)\n",
    "test_X = preprocessor_test.fit_transform(test_X)\n",
    "\n",
    "# Capture the feature names after transformation\n",
    "feature_names = preprocessor_train.get_feature_names_out()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d24967b-8a6c-4c9f-907b-f6f271d1e51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Train the regression model\n",
    "model = LinearRegression()\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# Make predictions\n",
    "pred_y = model.predict(test_X)\n",
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11198a1-055d-4ec7-a558-69d2daeacc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapie.regression import MapieRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the MapieRegressor with the Ridge regression model\n",
    "mapie = MapieRegressor(estimator=model)\n",
    "\n",
    "# Fit the MapieRegressor on the training data\n",
    "mapie.fit(train_X, train_y)\n",
    "\n",
    "# Function to get prediction interval for a single individual\n",
    "def get_prediction_interval(individual_features):\n",
    "    individual_features_processed = preprocessor_test.transform(individual_features)\n",
    "    y_pred, y_pis = mapie.predict(individual_features_processed, alpha=0.1) # predicted value oraz prediction interval\n",
    "    return y_pred[0], y_pis[0]\n",
    "\n",
    "# Convert X_test back to a DataFrame to process individual rows\n",
    "X_test_df = pd.DataFrame(test_X, columns=feature_names)\n",
    "\n",
    "# Apply to each individual in the test set\n",
    "results = []\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "NIE KOMPILUJE SIĘ\n",
    "\n",
    "for i in range(X_test_df.shape[0]):  # funkcja w nawiasie zwraca liczbę wierszy w zbiorze X_test \n",
    "    individual_features = X_test_df.iloc[[i]]  # funkcja wybiera wiersz o indeksie i ze zbioru X_test\n",
    "    y_pred, y_pis = get_prediction_interval(individual_features)\n",
    "    results.append((test_y.iloc[i], y_pred, y_pis))\n",
    "\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['True Value', 'Predicted Value', 'Prediction Interval'])\n",
    "print(results_df.head())\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
